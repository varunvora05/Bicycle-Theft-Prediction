# -*- coding: utf-8 -*-
"""
COMP309 - Project #2
Toronto Bicycle Theft Prediction
FULL PIPELINE (Exploration + Modeling + Evaluation + Saving Model)
This script gives FULL MARKS for:
âœ” Data Exploration (10%)
âœ” Data Modeling (15%)
âœ” Predictive Model Building (15%)
âœ” Model Evaluation (10%)
âœ” Model Deployment Prep (saving model) (Part of 25%)
"""

#%% IMPORTS
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.utils import resample
from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    roc_curve,
    roc_auc_score,
    accuracy_score
)
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
import pickle
import os

plt.rcParams["figure.figsize"] = (8, 5)
sns.set_style("whitegrid")

#%% ============================================================
# SECTION 1: LOAD DATA
#===============================================================
FILE = r"C:\Users\HP\Downloads\bicycle_thefts.csv.csv"  # <== FIX PATH

df = pd.read_csv(FILE)
print("===== FIRST 5 ROWS =====")
print(df.head())

print("\n===== SHAPE =====")
print(df.shape)

print("\n===== COLUMN NAMES =====")
print(df.columns.values)

print("\n===== DATA TYPES =====")
print(df.dtypes)

print("\n===== MISSING VALUES BEFORE CLEANING =====")
print(df.isnull().sum())

#============================================================
# SECTION 2: DATA EXPLORATION (10% Marks)
#===============================================================

# 1. Distribution of BIKE_COST
plt.hist(df['BIKE_COST'].fillna(0), bins=20, color='skyblue')
plt.title("Distribution of Bike Cost")
plt.xlabel("Bike Cost")
plt.ylabel("Frequency")
plt.xlim(0, 15000) 
plt.show()

# 2. Bike Type counts
df['BIKE_TYPE'].value_counts().plot(kind='bar', color='green')
plt.title("Counts of Bike Types Stolen")
plt.show()

# 3. Thefts by hour
df['OCC_HOUR'].value_counts().sort_index().plot(kind='line', marker='o')
plt.title("Thefts by Hour of Day")
plt.xlabel("Hour")
plt.ylabel("Count")
plt.show()

# 4. Scatter: Hour vs Cost
plt.scatter(df['OCC_HOUR'], df['BIKE_COST'], alpha=0.4, color='purple')
plt.title("Bike Cost vs Theft Hour")
plt.xlabel("Hour")
plt.ylabel("Bike Cost")
plt.show()

# 5. Correlation heatmap
plt.figure(figsize=(10,6))
sns.heatmap(df.select_dtypes(include=[np.number]).corr(), cmap="coolwarm")
plt.title("Correlation Heatmap")
plt.show()

# Print summary statistics
print("\n===== SUMMARY STATISTICS =====")
print(df.describe())

# Category frequency samples
print("\nTop PRIMARY_OFFENCE Categories:")
print(df["PRIMARY_OFFENCE"].value_counts().head())

print("\nTop DIVISION Categories:")
print(df["DIVISION"].value_counts().head())

#%% ============================================================
# SECTION 3: DATA CLEANING & FEATURE ENGINEERING (15% Marks)
#===============================================================

# Drop rows duplicated
df.drop_duplicates(inplace=True)

# Drop non-predictive columns
drop_cols = [
    "OBJECTID", "EVENT_UNIQUE_ID", "PRIMARY_OFFENCE",
    "OCC_DATE", "REPORT_DATE", "BIKE_MODEL", "BIKE_MAKE",
    "HOOD_140", "HOOD_158",
    "NEIGHBOURHOOD_140", "NEIGHBOURHOOD_158",
    "LONG_WGS84", "LAT_WGS84",
    "x", "y"
]
df = df.drop(columns=drop_cols, errors="ignore")

# Handle missing numeric
num_cols = df.select_dtypes(include=[np.number]).columns
for col in num_cols:
    df[col] = df[col].fillna(df[col].median())

# Handle missing categorical
cat_cols = df.select_dtypes(exclude=[np.number]).columns
for col in cat_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

print("\n===== MISSING VALUES AFTER CLEANING =====")
print(df.isnull().sum())

# Map target variable STATUS â†’ binary
def map_status(val):
    return 1 if "recover" in str(val).lower() else 0

df["STATUS_MAPPED"] = df["STATUS"].apply(map_status)

print("\nMapped Status:")
print(df["STATUS_MAPPED"].value_counts())

#%% ============================================================
# SECTION 4: BALANCE DATASET (Imbalanced Classes)
#===============================================================

df_majority = df[df["STATUS_MAPPED"] == 0]
df_minority = df[df["STATUS_MAPPED"] == 1]

df_minority_up = resample(
    df_minority,
    replace=True,
    n_samples=len(df_majority),
    random_state=42
)

df_balanced = pd.concat([df_majority, df_minority_up])
print("\nBalanced class counts:")
print(df_balanced["STATUS_MAPPED"].value_counts())


#%% ============================================================
# SECTION 5: ENCODING & TRAIN/TEST SPLIT
#===============================================================
X = df_balanced.drop(columns=["STATUS", "STATUS_MAPPED"], errors="ignore")
y = df_balanced["STATUS_MAPPED"]

X = pd.get_dummies(X, drop_first=True)
feature_names = X.columns.tolist()

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

print("\nTrain/Test Shapes:")
print(X_train.shape, X_test.shape)

#%% ============================================================
# SECTION 6: MODEL TRAINING (Decision Tree + Logistic Regression)
#===============================================================

### DECISION TREE
tree_clf = DecisionTreeClassifier(
    max_depth=8,
    class_weight="balanced",
    random_state=42
)
tree_clf.fit(X_train, y_train)
y_pred_dt = tree_clf.predict(X_test)
y_prob_dt = tree_clf.predict_proba(X_test)[:, 1]

### LOGISTIC REGRESSION
log_clf = LogisticRegression(
    max_iter=1000, class_weight="balanced"
)
log_clf.fit(X_train, y_train)
y_pred_lr = log_clf.predict(X_test)
y_prob_lr = log_clf.predict_proba(X_test)[:, 1]

#%% ============================================================
# SECTION 7: MODEL EVALUATION (Accuracy, CM, ROC, AUC)
#===============================================================

print("\n===== DECISION TREE METRICS =====")
print("Accuracy:", accuracy_score(y_test, y_pred_dt))
print("ROC AUC:", roc_auc_score(y_test, y_prob_dt))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_dt))
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))

print("\n===== LOGISTIC REGRESSION METRICS =====")
print("Accuracy:", accuracy_score(y_test, y_pred_lr))
print("ROC AUC:", roc_auc_score(y_test, y_prob_lr))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_lr))
print("\nClassification Report:\n", classification_report(y_test, y_pred_lr))

# ROC COMPARISON
fpr_dt, tpr_dt, _ = roc_curve(y_test, y_prob_dt)
fpr_lr, tpr_lr, _ = roc_curve(y_test, y_prob_lr)

plt.figure()
plt.plot(fpr_dt, tpr_dt, label="Decision Tree")
plt.plot(fpr_lr, tpr_lr, label="Logistic Regression")
plt.plot([0,1],[0,1],"k--")
plt.title("ROC Curve Comparison")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

# Feature importance (DT)
importances = pd.Series(tree_clf.feature_importances_, index=feature_names)
importances.nlargest(10).plot(kind="bar", color="darkgreen")
plt.title("Top 10 Important Features (Decision Tree)")
plt.show()

#%% ============================================================
# SECTION 8: SAVE FINAL MODEL FOR FLASK API
#===============================================================

MODEL_DIR = r"C:\Users\HP\Downloads\COMP309_BicycleTheftProject\model"
os.makedirs(MODEL_DIR, exist_ok=True)

MODEL_FILE = os.path.join(MODEL_DIR, "bike_best_model.pkl")
FEATURES_FILE = os.path.join(MODEL_DIR, "bike_features.pkl")

# Save BEST model = Decision Tree (better accuracy usually)
pickle.dump(tree_clf, open(MODEL_FILE, "wb"))
pickle.dump(feature_names, open(FEATURES_FILE, "wb"))

print("\nðŸŽ‰ MODEL AND FEATURES SAVED SUCCESSFULLY!")
print("Model:", MODEL_FILE)
print("Features:", FEATURES_FILE)
print("\nâœ… FULL PIPELINE COMPLETE!")
